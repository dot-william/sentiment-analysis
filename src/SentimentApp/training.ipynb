{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Regex\n",
    "import re \n",
    "\n",
    "# NLTK\n",
    "import nltk #for text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import  MultinomialNB\n",
    "from joblib import dump, load\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:14: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  df_1['tweet'] = df_1['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:14: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  df_1['tweet'] = df_1['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:15: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  df_2['tweet'] = df_2['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:15: DeprecationWarning: invalid escape sequence '\\i'\n",
      "  df_2['tweet'] = df_2['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:15: DeprecationWarning: invalid escape sequence '\\('\n",
      "  df_2['tweet'] = df_2['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:15: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  df_2['tweet'] = df_2['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:15: DeprecationWarning: invalid escape sequence '\\o'\n",
      "  df_2['tweet'] = df_2['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:16: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  df_3['tweet'] = df_3['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:16: DeprecationWarning: invalid escape sequence '\\_'\n",
      "  df_3['tweet'] = df_3['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:16: DeprecationWarning: invalid escape sequence '\\/'\n",
      "  df_3['tweet'] = df_3['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:16: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  df_3['tweet'] = df_3['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:17: DeprecationWarning: invalid escape sequence '\\('\n",
      "  df_4['tweet'] = df_4['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:18: DeprecationWarning: invalid escape sequence '\\o'\n",
      "  df_5['tweet'] = df_5['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
      "C:\\Users\\WDIMACULANGAN\\AppData\\Local\\Temp\\ipykernel_14404\\1201518197.py:22: DeprecationWarning: invalid escape sequence '\\m'\n",
      "  df_10['tweet'] = df_10['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape').lower())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260097528899452929</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Won the match #getin . Plus, tomorrow is a ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263791921753882624</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Some areas of New England could see the first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264194578381410304</td>\n",
       "      <td>negative</td>\n",
       "      <td>@francesco_con40 2nd worst QB. DEFINITELY Tony...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264041328420204544</td>\n",
       "      <td>neutral</td>\n",
       "      <td>#Thailand Washington - US President Barack Oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263816256640126976</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Did y’all hear what Tony Romo dressed up as fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>@racalto_sk ok good to know. punting at metlif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>anybody want a ticket for tomorrow colombia vs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mendez told me he'd drive me to metlife on sun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27451 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     260097528899452929   neutral   \n",
       "1     263791921753882624   neutral   \n",
       "2     264194578381410304  negative   \n",
       "3     264041328420204544   neutral   \n",
       "4     263816256640126976   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  \n",
       "0     Won the match #getin . Plus, tomorrow is a ver...  \n",
       "1     Some areas of New England could see the first ...  \n",
       "2     @francesco_con40 2nd worst QB. DEFINITELY Tony...  \n",
       "3     #Thailand Washington - US President Barack Oba...  \n",
       "4     Did y’all hear what Tony Romo dressed up as fo...  \n",
       "...                                                 ...  \n",
       "5863  @racalto_sk ok good to know. punting at metlif...  \n",
       "5864  everyone who sat around me at metlife was so a...  \n",
       "5865  what giants or niners fans would wanna go to t...  \n",
       "5866  anybody want a ticket for tomorrow colombia vs...  \n",
       "5867  mendez told me he'd drive me to metlife on sun...  \n",
       "\n",
       "[27451 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data and concatenating\n",
    "df_1 = pd.read_csv('datasets/twitter-2013dev-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_2 = pd.read_csv('datasets/twitter-2013test-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_3 = pd.read_csv('datasets/twitter-2013train-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_4 = pd.read_csv('datasets/twitter-2014test-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_5 = pd.read_csv('datasets/twitter-2015test-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_6 = pd.read_csv('datasets/twitter-2015train-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_7 = pd.read_csv('datasets/twitter-2016dev-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_8 = pd.read_csv('datasets/twitter-2016devtest-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "# df_9 = pd.read_csv('datasets/twitter-2016test-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "df_10 = pd.read_csv('datasets/twitter-2016train-A.txt', delimiter='\\t', names=['id', 'sentiment', 'tweet']) \n",
    "\n",
    "# Decode unicode-escape characters and convert everything to lowercase\n",
    "df_1['tweet'] = df_1['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "df_2['tweet'] = df_2['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "df_3['tweet'] = df_3['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "df_4['tweet'] = df_4['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "df_5['tweet'] = df_5['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "df_6['tweet'] = df_6['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "df_7['tweet'] = df_7['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape'))\n",
    "# df_8['tweet'] = df_8['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode_escape')) # UnicodeDecodeError: 'unicodeescape' codec can't decode byte 0x5c in position 139: \\ at end of string\n",
    "df_10['tweet'] = df_10['tweet'].apply(lambda x: x.encode('utf-8').decode('unicode-escape').lower())\n",
    "\n",
    "# Concatenate dataframes\n",
    "tweets_df = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_10],axis=0)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if sentiment is correct unique in the dataframe\n",
    "tweets_df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WDIMACULANGAN\\Desktop\\Activity\\venv\\py-activity\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\WDIMACULANGAN\\Desktop\\Activity\\venv\\py-activity\\lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\WDIMACULANGAN\\Desktop\\Activity\\venv\\py-activity\\lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sentiment Distribution')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot number of sentiments to get an idea of the distribution\n",
    "plt.figure()\n",
    "sns.histplot(data=tweets_df, x=tweets_df['sentiment'])\n",
    "plt.title(\"Sentiment Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the data that there is an imbalance in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, let us preprocess the dataset. The following will be done to apply preprocessing on the data:\n",
    "1. Unicode escape sequence `\\u` will be decoded.\n",
    "2. Punctuations will be  removed.\n",
    "3. Links will be removed.\n",
    "4. `#` and `@` characters will also be removed from the texts, but the word following it will be retained.\n",
    "5. Numbers will be removed but numbers following letters (e.g. 2nd, 16th) will be retained\n",
    "\n",
    "After cleaning the text, preprocessing, the following steps will be done:\n",
    "1. Words will be tokenized.\n",
    "2. After tokenization, words will be lemmatized\n",
    "3. After lemmatization, stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes @, #, and punctuation marks from the text.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): tokenized tweet.\n",
    "    Returns:\n",
    "        str: The cleaned tweet text.\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace @, #, links and non-word characters with a space\n",
    "    pattern = re.compile(r'(http|https)://[^\\s]+|[^\\w\\s@#]|[@#]|\\d+:\\d+|\\d+(?![a-zA-Z])|_')\n",
    "    cleaned_text = pattern.sub(' ', text)\n",
    "\n",
    "    \n",
    "\n",
    "    # Remove extra spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    return cleaned_text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the text.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): tokenized tweet.\n",
    "    Returns:\n",
    "        str: The cleaned tweet text.\n",
    "    \"\"\"\n",
    "    # Clean text\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(cleaned_text)\n",
    "    filtered_words = []\n",
    "    \n",
    "    # Remove English Stop Words\n",
    "    stop_words = stopwords.words('English')\n",
    "    stop_words.remove(\"not\")\n",
    "    stop_words = set(stop_words)\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    # print(\"Filtered: \", filtered_words)\n",
    "    \n",
    "    # Lemmatize the text for nouns\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = []\n",
    "    for word in filtered_words:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, pos='n')\n",
    "        lemmatized_words.append(lemmatized_word) \n",
    "    # print(\"Lemmatized words:\", lemmatized_words)\n",
    "\n",
    "    # Lemmatize for verbs\n",
    "    final_lemmatized_words = []\n",
    "    for word in lemmatized_words:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, pos='v')\n",
    "        final_lemmatized_words.append(lemmatized_word)\n",
    "    \n",
    "    processed_text = ' '.join(final_lemmatized_words)\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# stop_words = set(stopwords.words('English'))\n",
    "stop_list = stopwords.words('English')\n",
    "stop_list.remove(\"me\")\n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'about', 'on', 'hasn', 'm', 'up', 'very', 'while', 'be', \"haven't\", 'other', \"weren't\", 'yours', 'itself', 'themselves', 'why', 'how', \"wasn't\", \"it's\", 'nor', 'whom', 'over', 'after', 'should', 'through', 'its', 'of', 'not', 'there', 'been', 'few', \"should've\", 'further', 'ours', 'a', \"you'll\", 'ain', 'to', \"shouldn't\", 'doing', 'off', 'now', 'until', 'herself', 'did', 'once', 'won', 'an', 'as', 'with', 'hers', \"doesn't\", 'having', 'when', 'the', 'here', 'our', 'no', 'she', 'shouldn', 'didn', \"isn't\", 'yourself', 'is', 'if', 're', 'from', \"couldn't\", 'they', \"aren't\", 'or', 'you', 'himself', 'out', 'during', 'any', 'just', 'weren', 'at', 'ourselves', 'isn', \"shan't\", \"mightn't\", 'theirs', 'most', \"that'll\", 'them', 'same', 'will', \"hasn't\", 'because', \"she's\", 'aren', 'your', 'this', 'd', 'doesn', 'll', 'below', 'wasn', 'don', 'my', 'that', 'who', 'has', 'their', 'these', 'shan', 'each', 'him', 'both', 'before', \"you're\", 't', \"needn't\", 'does', 'those', 'her', 'only', 'he', 'again', 'wouldn', 'such', 'am', 'down', 'under', 'have', 'own', 's', \"you'd\", 'more', 'are', 'but', 've', 'yourselves', 'his', \"you've\", 'and', 'me', 'then', 'mustn', 'couldn', 'hadn', 'o', 'needn', 'do', 'being', 'it', 'in', 'between', 'had', \"wouldn't\", 'what', 'can', 'than', 'were', 'so', 'y', \"don't\", 'which', 'above', \"mustn't\", 'was', 'against', 'some', \"didn't\", 'haven', 'myself', \"hadn't\", 'mightn', 'i', 'ma', 'into', 'where', \"won't\", 'by', 'all', 'for', 'we', 'too'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2nd not do update hurray ahehe go sleep six load pa ang bubunuin ko tomorrow aja god bless everyone'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(stopwords.words('English')))\n",
    "# WordNetLemmatizer().lemmatize(\"us\", pos='n')\n",
    "text = \"2nd not 2 Done with the updates! Hurray for me!! Ahehe^_^ Now I can go to sleep. Six loads pa ang bubunuin ko tomorrow...Aja! God bless everyone:)\"\n",
    "\n",
    "preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['cleaned_tokenized_text'] = tweets_df['tweet'].apply(preprocess_text)\n",
    "# tweets_df.to_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260097528899452929</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Won the match #getin . Plus, tomorrow is a ver...</td>\n",
       "      <td>match getin plus tomorrow busy day awareness d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263791921753882624</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Some areas of New England could see the first ...</td>\n",
       "      <td>area new england could see first flake season ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264194578381410304</td>\n",
       "      <td>negative</td>\n",
       "      <td>@francesco_con40 2nd worst QB. DEFINITELY Tony...</td>\n",
       "      <td>francesco con 2nd worst qb definitely tony rom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264041328420204544</td>\n",
       "      <td>neutral</td>\n",
       "      <td>#Thailand Washington - US President Barack Oba...</td>\n",
       "      <td>thailand washington u president barack obama v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263816256640126976</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Did y’all hear what Tony Romo dressed up as fo...</td>\n",
       "      <td>hear tony romo dress halloween giant quaterbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>@racalto_sk ok good to know. punting at metlif...</td>\n",
       "      <td>racalto sk ok good know punt metlife december ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "      <td>everyone sit around metlife annoy didnt let ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "      <td>giant niner fan would wan na go sunday night g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>anybody want a ticket for tomorrow colombia vs...</td>\n",
       "      <td>anybody want ticket tomorrow colombia v peru m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mendez told me he'd drive me to metlife on sun...</td>\n",
       "      <td>mendez tell drive metlife sunday reaction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27451 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "0     260097528899452929   neutral   \n",
       "1     263791921753882624   neutral   \n",
       "2     264194578381410304  negative   \n",
       "3     264041328420204544   neutral   \n",
       "4     263816256640126976   neutral   \n",
       "...                  ...       ...   \n",
       "5863  639855845958885376  positive   \n",
       "5864  639979760735662080   neutral   \n",
       "5865  640196838260363269   neutral   \n",
       "5866  640975710354567168  positive   \n",
       "5867  641034340068143104   neutral   \n",
       "\n",
       "                                                  tweet  \\\n",
       "0     Won the match #getin . Plus, tomorrow is a ver...   \n",
       "1     Some areas of New England could see the first ...   \n",
       "2     @francesco_con40 2nd worst QB. DEFINITELY Tony...   \n",
       "3     #Thailand Washington - US President Barack Oba...   \n",
       "4     Did y’all hear what Tony Romo dressed up as fo...   \n",
       "...                                                 ...   \n",
       "5863  @racalto_sk ok good to know. punting at metlif...   \n",
       "5864  everyone who sat around me at metlife was so a...   \n",
       "5865  what giants or niners fans would wanna go to t...   \n",
       "5866  anybody want a ticket for tomorrow colombia vs...   \n",
       "5867  mendez told me he'd drive me to metlife on sun...   \n",
       "\n",
       "                                 cleaned_tokenized_text  \n",
       "0     match getin plus tomorrow busy day awareness d...  \n",
       "1     area new england could see first flake season ...  \n",
       "2     francesco con 2nd worst qb definitely tony rom...  \n",
       "3     thailand washington u president barack obama v...  \n",
       "4     hear tony romo dress halloween giant quaterbac...  \n",
       "...                                                 ...  \n",
       "5863  racalto sk ok good know punt metlife december ...  \n",
       "5864  everyone sit around metlife annoy didnt let ru...  \n",
       "5865  giant niner fan would wan na go sunday night g...  \n",
       "5866  anybody want ticket tomorrow colombia v peru m...  \n",
       "5867          mendez tell drive metlife sunday reaction  \n",
       "\n",
       "[27451 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 231)\t0.7022235374236776\n",
      "  (0, 225)\t0.36293270771046665\n",
      "  (0, 143)\t0.3683113918521068\n",
      "  (0, 906)\t0.14366142135801446\n",
      "  (0, 682)\t0.34826083701245103\n",
      "  (0, 548)\t0.31238511041800887\n",
      "  (1, 922)\t0.3164471755046449\n",
      "  (1, 779)\t0.32343884891538704\n",
      "  (1, 326)\t0.3127935195723125\n",
      "  (1, 781)\t0.23963876142931895\n",
      "  (1, 206)\t0.36026808167657925\n",
      "  (1, 276)\t0.46199633798870954\n",
      "  (1, 607)\t0.2741511991354224\n",
      "  (1, 60)\t0.47073281942554085\n",
      "  (2, 873)\t0.2570699105025815\n",
      "  (2, 430)\t0.34469622316832554\n",
      "  (2, 292)\t0.28426651972501354\n",
      "  (2, 80)\t0.3187447818759387\n",
      "  (2, 796)\t0.33265178524171063\n",
      "  (2, 509)\t0.19602552145023025\n",
      "  (2, 539)\t0.2626368887180149\n",
      "  (2, 752)\t0.361569362000011\n",
      "  (2, 237)\t0.344019456023526\n",
      "  (2, 980)\t0.348962403638129\n",
      "  (2, 4)\t0.2092271139825006\n",
      "  :\t:\n",
      "  (27447, 561)\t0.4514555700853396\n",
      "  (27447, 61)\t0.41751003692505007\n",
      "  (27447, 40)\t0.41791688280137346\n",
      "  (27447, 811)\t0.31664537120491304\n",
      "  (27447, 503)\t0.36088919264740715\n",
      "  (27447, 615)\t0.2514506639257998\n",
      "  (27447, 292)\t0.3917728672476277\n",
      "  (27448, 561)\t0.41457369259715565\n",
      "  (27448, 982)\t0.30957529418312546\n",
      "  (27448, 596)\t0.2927755474990641\n",
      "  (27448, 949)\t0.3700279372070085\n",
      "  (27448, 305)\t0.3418486178704058\n",
      "  (27448, 355)\t0.24804587108277132\n",
      "  (27448, 363)\t0.19377706546886067\n",
      "  (27448, 615)\t0.23090828235881466\n",
      "  (27448, 862)\t0.2441350222190623\n",
      "  (27448, 359)\t0.4252014444614447\n",
      "  (27449, 561)\t0.6693236101429628\n",
      "  (27449, 950)\t0.4394253816873389\n",
      "  (27449, 893)\t0.5296665090247555\n",
      "  (27449, 906)\t0.2799368286804293\n",
      "  (27450, 561)\t0.5826303292220577\n",
      "  (27450, 876)\t0.48401359968262286\n",
      "  (27450, 262)\t0.5554770353027493\n",
      "  (27450, 862)\t0.34310056549666973\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "matrix = vectorizer.fit_transform(tweets_df['cleaned_tokenized_text'])\n",
    "# Save the vectorizer\n",
    "dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 764)\t0.4624064537435919\n",
      "  (0, 838)\t0.38881501837036286\n",
      "  (0, 746)\t0.43565423383090146\n",
      "  (0, 893)\t0.37314472924752756\n",
      "  (0, 355)\t0.2821247618976834\n",
      "  (0, 769)\t0.2769843466085776\n",
      "  (0, 481)\t0.3179318885907616\n",
      "  (0, 363)\t0.22039999383175107\n",
      "  (1, 705)\t0.3335016242689916\n",
      "  (1, 147)\t0.3820889292238473\n",
      "  (1, 357)\t0.39718987681436685\n",
      "  (1, 387)\t0.37529674769359034\n",
      "  (1, 96)\t0.37885532148552525\n",
      "  (1, 224)\t0.3135456809289375\n",
      "  (1, 610)\t0.277458214831801\n",
      "  (1, 701)\t0.35405078742544577\n",
      "  (2, 542)\t0.464975979973873\n",
      "  (2, 953)\t0.34899912388972903\n",
      "  (2, 406)\t0.561080486693874\n",
      "  (2, 796)\t0.5892246065999818\n",
      "  (3, 45)\t0.3181533146533444\n",
      "  (3, 925)\t0.38347603844386896\n",
      "  (3, 538)\t0.27473060002061306\n",
      "  (3, 907)\t0.2894202481697938\n",
      "  (3, 461)\t0.4191930693670246\n",
      "  :\t:\n",
      "  (19210, 360)\t0.24925203458696946\n",
      "  (19210, 550)\t0.14117077651957488\n",
      "  (19210, 509)\t0.17891699766530503\n",
      "  (19211, 878)\t0.3865283380158787\n",
      "  (19211, 522)\t0.2715553716939509\n",
      "  (19211, 243)\t0.39600058596101395\n",
      "  (19211, 774)\t0.32120549785412933\n",
      "  (19211, 839)\t0.5546402768497309\n",
      "  (19211, 950)\t0.25842857078667625\n",
      "  (19211, 581)\t0.26373398582337904\n",
      "  (19211, 78)\t0.26999501828845085\n",
      "  (19212, 473)\t0.8587011179357035\n",
      "  (19212, 620)\t0.5124767214771546\n",
      "  (19213, 861)\t0.3977170893170534\n",
      "  (19213, 195)\t0.33153276767275003\n",
      "  (19213, 903)\t0.3609223404094819\n",
      "  (19213, 899)\t0.3268400508254009\n",
      "  (19213, 952)\t0.5738315896746549\n",
      "  (19213, 326)\t0.40686004090555167\n",
      "  (19214, 666)\t0.41650635332231556\n",
      "  (19214, 916)\t0.49435630554607507\n",
      "  (19214, 803)\t0.30676200953061555\n",
      "  (19214, 828)\t0.4243326654993729\n",
      "  (19214, 380)\t0.48820908302490423\n",
      "  (19214, 346)\t0.2638655918453567\n",
      "4950     neutral\n",
      "2092     neutral\n",
      "3131     neutral\n",
      "920      neutral\n",
      "824      neutral\n",
      "          ...   \n",
      "4308     neutral\n",
      "1929    negative\n",
      "4997    negative\n",
      "3598    positive\n",
      "178     positive\n",
      "Name: sentiment, Length: 19215, dtype: object\n"
     ]
    }
   ],
   "source": [
    "features = matrix\n",
    "\n",
    "labels = tweets_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=77, test_size=0.3, shuffle=True)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WDIMACULANGAN\\Desktop\\Activity\\venv\\py-activity\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.27      0.37      1290\n",
      "     neutral       0.60      0.73      0.66      3527\n",
      "    positive       0.68      0.67      0.68      3419\n",
      "\n",
      "    accuracy                           0.63      8236\n",
      "   macro avg       0.62      0.56      0.57      8236\n",
      "weighted avg       0.63      0.63      0.62      8236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is inadequate, therefore let's try to use a random under sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    11726\n",
       "neutral     11494\n",
       "negative     4231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "negative    4231\n",
      "neutral     4231\n",
      "positive    4231\n",
      "Name: count, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.65      0.63      1250\n",
      "     neutral       0.56      0.57      0.57      1322\n",
      "    positive       0.64      0.60      0.62      1236\n",
      "\n",
      "    accuracy                           0.60      3808\n",
      "   macro avg       0.61      0.60      0.61      3808\n",
      "weighted avg       0.61      0.60      0.60      3808\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WDIMACULANGAN\\Desktop\\Activity\\venv\\py-activity\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Random Undersampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "X_res, y_res = rus.fit_resample(features, labels)\n",
    "\n",
    "print(y_res.value_counts())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, random_state=77, test_size=0.3, shuffle=True)\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the other metrics have improved after balancing the dataset, let us try using other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Models\n",
    "\n",
    "# svm = SVC(random_state=77, kernel='linear', probability=True)\n",
    "# dt = DecisionTreeClassifier(random_state=77)\n",
    "# rf = RandomForestClassifier(random_state=77)\n",
    "# nb = MultinomialNB()\n",
    "# models = {'SVM': svm, 'Decision Trees': dt,\"Random Forest\": rf, \"Naive Bayes\": nb}\n",
    "# trained_models = {}\n",
    "\n",
    "# print(y_train.value_counts())\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     prediction = model.predict(X_test)\n",
    "#     print(f\"{name}\", classification_report(y_test, prediction))\n",
    "#     print('\\n')\n",
    "#     # Save the model\n",
    "#     dump(model, f\"{name}_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the saved result\n",
    "```\n",
    "sentiment\n",
    "positive    2995\n",
    "negative    2981\n",
    "neutral     2909\n",
    "Name: count, dtype: int64\n",
    "SVM               precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.59      0.64      0.61      1250\n",
    "     neutral       0.55      0.58      0.56      1322\n",
    "    positive       0.67      0.57      0.62      1236\n",
    "\n",
    "    accuracy                           0.60      3808\n",
    "   macro avg       0.60      0.60      0.60      3808\n",
    "weighted avg       0.60      0.60      0.60      3808\n",
    "\n",
    "\n",
    "\n",
    "Decision Trees               precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.49      0.53      0.51      1250\n",
    "     neutral       0.50      0.46      0.48      1322\n",
    "    positive       0.55      0.54      0.54      1236\n",
    "\n",
    "    accuracy                           0.51      3808\n",
    "   macro avg       0.51      0.51      0.51      3808\n",
    "weighted avg       0.51      0.51      0.51      3808\n",
    "\n",
    "\n",
    "\n",
    "Random Forest               precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.56      0.61      0.58      1250\n",
    "     neutral       0.54      0.56      0.55      1322\n",
    "    positive       0.66      0.58      0.62      1236\n",
    "\n",
    "    accuracy                           0.58      3808\n",
    "   macro avg       0.59      0.58      0.58      3808\n",
    "weighted avg       0.59      0.58      0.58      3808\n",
    "\n",
    "\n",
    "\n",
    "Naive Bayes               precision    recall  f1-score   support\n",
    "\n",
    "    negative       0.59      0.64      0.62      1250\n",
    "     neutral       0.55      0.51      0.53      1322\n",
    "    positive       0.60      0.59      0.60      1236\n",
    "\n",
    "    accuracy                           0.58      3808\n",
    "   macro avg       0.58      0.58      0.58      3808\n",
    "weighted avg       0.58      0.58      0.58      3808\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preform_gridsearchcv(model_name, model, model_params, X_train, y_train):\n",
    "    grid_search_model = GridSearchCV(model, model_params, cv=5)\n",
    "    grid_search_model.fit(X_train, y_train)\n",
    "\n",
    "    # Get best parameters\n",
    "    best_params = grid_search_model.best_params_\n",
    "    best_estimator = grid_search_model.best_estimator_\n",
    "    print(f\"{model_name} Best Parameters:\")\n",
    "    print(best_params)\n",
    "    print(f\"{model_name} Best Estimators:\")\n",
    "    print(best_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare models again\n",
    "svm = SVC(random_state=77, probability=True)\n",
    "dt = DecisionTreeClassifier(random_state=77)\n",
    "rf = RandomForestClassifier(random_state=77)\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Naive Bayes Hyperparameter Tuning\n",
    "# naive_bayes_params = {'alpha': [0.1, 0.5, 1, 2]}\n",
    "# preform_gridsearchcv(\"Naive Bayes\", nb, naive_bayes_params, X_train, y_train)\n",
    "\n",
    "# # SVM\n",
    "# svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "# preform_gridsearchcv(\"SVM\", svm, svm_params, X_train, y_train)\n",
    "\n",
    "# # Decision Trees\n",
    "# decision_tree_params = {'criterion': ['gini', 'entropy'], 'max_depth': [None, 10, 20, 30, 40, 50]}\n",
    "# preform_gridsearchcv(\"Decision Trees\", dt, decision_tree_params, X_train, y_train)\n",
    "\n",
    "# # Random Forest\n",
    "# random_forest_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20, 30]}\n",
    "# preform_gridsearchcv(\"Random Forest\", rf, random_forest_params, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Naive Bayes Best Parameters:\n",
    "{'alpha': 2}\n",
    "Naive Bayes Best Estimators:\n",
    "MultinomialNB(alpha=2)\n",
    "SVM Best Parameters:\n",
    "{'C': 1, 'kernel': 'rbf'}\n",
    "SVM Best Estimators:\n",
    "SVC(C=1, probability=True, random_state=77)\n",
    "Decision Trees Best Parameters:\n",
    "{'criterion': 'gini', 'max_depth': None}\n",
    "Decision Trees Best Estimators:\n",
    "DecisionTreeClassifier(random_state=77)\n",
    "Random Forest Best Parameters:\n",
    "{'max_depth': None, 'n_estimators': 100}\n",
    "Random Forest Best Estimators:\n",
    "RandomForestClassifier(random_state=77)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    2995\n",
      "negative    2981\n",
      "neutral     2909\n",
      "Name: count, dtype: int64\n",
      "SVM               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.65      0.63      1250\n",
      "     neutral       0.56      0.60      0.58      1322\n",
      "    positive       0.67      0.57      0.61      1236\n",
      "\n",
      "    accuracy                           0.61      3808\n",
      "   macro avg       0.61      0.61      0.61      3808\n",
      "weighted avg       0.61      0.61      0.61      3808\n",
      "\n",
      "\n",
      "\n",
      "Decision Trees               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.53      0.51      1250\n",
      "     neutral       0.49      0.46      0.47      1322\n",
      "    positive       0.55      0.55      0.55      1236\n",
      "\n",
      "    accuracy                           0.51      3808\n",
      "   macro avg       0.51      0.51      0.51      3808\n",
      "weighted avg       0.51      0.51      0.51      3808\n",
      "\n",
      "\n",
      "\n",
      "Random Forest               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.63      0.60      1250\n",
      "     neutral       0.55      0.58      0.57      1322\n",
      "    positive       0.67      0.57      0.62      1236\n",
      "\n",
      "    accuracy                           0.59      3808\n",
      "   macro avg       0.60      0.59      0.59      3808\n",
      "weighted avg       0.60      0.59      0.59      3808\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.66      0.62      1250\n",
      "     neutral       0.56      0.50      0.53      1322\n",
      "    positive       0.61      0.60      0.60      1236\n",
      "\n",
      "    accuracy                           0.59      3808\n",
      "   macro avg       0.59      0.59      0.59      3808\n",
      "weighted avg       0.59      0.59      0.58      3808\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuned\n",
    "svm = SVC(C=1, kernel= 'rbf', random_state=77, probability=True)\n",
    "dt = DecisionTreeClassifier(criterion= 'gini', max_depth= None, random_state=77)\n",
    "rf = RandomForestClassifier(max_depth= None, n_estimators=100, random_state=77)\n",
    "nb = MultinomialNB(alpha=2)\n",
    "\n",
    "models = {'SVM': svm, 'Decision Trees': dt,\"Random Forest\": rf, \"Naive Bayes\": nb}\n",
    "trained_models = {}\n",
    "\n",
    "print(y_train.value_counts())\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    print(f\"{name}\", classification_report(y_test, prediction))\n",
    "    print('\\n')\n",
    "    # Save the model\n",
    "    dump(model, f\"{name}_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go bull game next thursday'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"Going to a bulls game next Thursday\"\n",
    "\n",
    "cleaned_input = preprocess_text(user_input)\n",
    "cleaned_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: ['positive']\n",
      "Probability Estimates: [[0.2777904  0.01337028 0.70883932]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load('SVM_model.joblib')\n",
    "vectorizer = load('tfidf_vectorizer.joblib')\n",
    "user_input = \"I am not happy\"\n",
    "\n",
    "cleaned_input = preprocess_text(user_input)\n",
    "user_input_tfidf = vectorizer.transform([cleaned_input])\n",
    "\n",
    "predicted_label = loaded_model.predict(user_input_tfidf)\n",
    "\n",
    "probability_estimates = loaded_model.predict_proba(user_input_tfidf)\n",
    "\n",
    "print(\"Predicted Label:\", predicted_label)\n",
    "print(\"Probability Estimates:\", probability_estimates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-acts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
